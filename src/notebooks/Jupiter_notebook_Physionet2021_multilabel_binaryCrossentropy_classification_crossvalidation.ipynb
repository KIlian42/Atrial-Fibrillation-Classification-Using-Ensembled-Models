{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UPiaiebnCYov"
      },
      "outputs": [],
      "source": [
        "# == Hyperparameter configuration ==\n",
        "\n",
        "# Official scored labels Physionet 2021: https://github.com/physionetchallenges/evaluation-2021/blob/main/dx_mapping_scored.csv\n",
        "\n",
        "# 0 = 426783006 -> sinus rhythm (SR)\n",
        "# 1 = 164889003 -> atrial fibrillation (AF)\n",
        "# 2 = 164890007 -> atrial flutter (AFL)\n",
        "# 3 = 284470004 or 63593006 -> premature atrial contraction (PAC) or supraventricular premature beats (SVPB)\n",
        "# 4 = 427172004 or 17338001 -> premature ventricular contractions (PVC), ventricular premature beats (VPB)\n",
        "# 5 = 6374002 -> bundle branch block (BBB)\n",
        "# 6 = 426627000 -> bradycardia (Brady)\n",
        "# 7 = 733534002 or 164909002 -> complete left bundle branch block (CLBBB), left bundle branch block (LBBB)\n",
        "# 8 = 713427006 or 59118001 -> complete right bundle branch block (CRBBB), right bundle branch block (RBBB)\n",
        "# 9 = 270492004 -> 1st degree av block (IAVB)\n",
        "# 10 = 713426002 -> incomplete right bundle branch block (IRBBB)\n",
        "# 11 = 39732003 -> left axis deviation (LAD)\n",
        "# 12 = 445118002 -> left anterior fascicular block (LAnFB)\n",
        "# 13 = 251146004 -> low qrs voltages (LQRSV)\n",
        "# 14 = 698252002 -> nonspecific intraventricular conduction disorder (NSIVCB)\n",
        "# 15 = 10370003 -> pacing rhythm (PR)\n",
        "# 16 = 365413008 -> poor R wave Progression (PRWP)\n",
        "# 17 = 164947007 -> prolonged pr interval (LPR)\n",
        "# 18 = 111975006 -> prolonged qt interval (LQT)\n",
        "# 19 = 164917005 -> qwave abnormal (QAb)\n",
        "# 20 = 47665007 -> right axis deviation (RAD)\n",
        "# 21 = 427393009 -> sinus arrhythmia (SA)\n",
        "# 22 = 426177001 -> sinus bradycardia (SB)\n",
        "# 23 = 427084000 -> sinus tachycardia (STach)\n",
        "# 24 = 164934002 -> t wave abnormal (TAb)\n",
        "# 25 = 59931005 -> t wave inversion (TInv)\n",
        "\n",
        "VALID_LABELS = set(\n",
        "    [\n",
        "        \"164889003\",\n",
        "        \"164890007\",\n",
        "        \"6374002\",\n",
        "        \"426627000\",\n",
        "        \"733534002\",\n",
        "        \"713427006\",\n",
        "        \"270492004\",\n",
        "        \"713426002\",\n",
        "        \"39732003\",\n",
        "        \"445118002\",\n",
        "        \"164909002\",\n",
        "        \"251146004\",\n",
        "        \"698252002\",\n",
        "        \"426783006\",\n",
        "        \"284470004\",\n",
        "        \"10370003\",\n",
        "        \"365413008\",\n",
        "        \"427172004\",\n",
        "        \"164947007\",\n",
        "        \"111975006\",\n",
        "        \"164917005\",\n",
        "        \"47665007\",\n",
        "        \"59118001\",\n",
        "        \"427393009\",\n",
        "        \"426177001\",\n",
        "        \"427084000\",\n",
        "        \"63593006\",\n",
        "        \"164934002\",\n",
        "        \"59931005\",\n",
        "        \"17338001\",\n",
        "    ]\n",
        ")\n",
        "# VALID_LABELS = set([\"426783006\", \"164889003\", \"164890007\", \"284470004\", \"427172004\"]) # SR, AF, AFL, PAC, PVC\n",
        "NUM_CLASSES =  26\n",
        "EPOCHS = 50\n",
        "LEARNING_RATE = 0.001\n",
        "BATCH_SIZE = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68ZDikRKCZ6_",
        "outputId": "8b73ecd8-7954-4f01-fcab-a47cf2df8bda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Jul  8 17:46:17 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# == Check if GPU is available ==\n",
        "\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEnUK8J5zqBe",
        "outputId": "620afe14-db60-468b-9661-5edb84ede978"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-colab in /usr/local/lib/python3.10/dist-packages (1.0.0)\n",
            "Requirement already satisfied: google-auth==2.27.0 in /usr/local/lib/python3.10/dist-packages (from google-colab) (2.27.0)\n",
            "Requirement already satisfied: ipykernel==5.5.6 in /usr/local/lib/python3.10/dist-packages (from google-colab) (5.5.6)\n",
            "Requirement already satisfied: ipyparallel==8.8.0 in /usr/local/lib/python3.10/dist-packages (from google-colab) (8.8.0)\n",
            "Requirement already satisfied: ipython==7.34.0 in /usr/local/lib/python3.10/dist-packages (from google-colab) (7.34.0)\n",
            "Requirement already satisfied: notebook==6.5.5 in /usr/local/lib/python3.10/dist-packages (from google-colab) (6.5.5)\n",
            "Requirement already satisfied: pandas==2.0.3 in /usr/local/lib/python3.10/dist-packages (from google-colab) (2.0.3)\n",
            "Requirement already satisfied: portpicker==1.5.2 in /usr/local/lib/python3.10/dist-packages (from google-colab) (1.5.2)\n",
            "Requirement already satisfied: requests==2.31.0 in /usr/local/lib/python3.10/dist-packages (from google-colab) (2.31.0)\n",
            "Requirement already satisfied: tornado==6.3.3 in /usr/local/lib/python3.10/dist-packages (from google-colab) (6.3.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth==2.27.0->google-colab) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth==2.27.0->google-colab) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth==2.27.0->google-colab) (4.9)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from ipykernel==5.5.6->google-colab) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel==5.5.6->google-colab) (5.7.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel==5.5.6->google-colab) (6.1.12)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipyparallel==8.8.0->google-colab) (4.4.2)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from ipyparallel==8.8.0->google-colab) (0.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ipyparallel==8.8.0->google-colab) (5.9.5)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.10/dist-packages (from ipyparallel==8.8.0->google-colab) (2.8.2)\n",
            "Requirement already satisfied: pyzmq>=18 in /usr/local/lib/python3.10/dist-packages (from ipyparallel==8.8.0->google-colab) (24.0.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from ipyparallel==8.8.0->google-colab) (4.66.4)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython==7.34.0->google-colab) (67.7.2)\n",
            "Collecting jedi>=0.16 (from ipython==7.34.0->google-colab)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython==7.34.0->google-colab) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython==7.34.0->google-colab) (3.0.47)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython==7.34.0->google-colab) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython==7.34.0->google-colab) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython==7.34.0->google-colab) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython==7.34.0->google-colab) (4.9.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from notebook==6.5.5->google-colab) (3.1.4)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook==6.5.5->google-colab) (23.1.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from notebook==6.5.5->google-colab) (5.7.2)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from notebook==6.5.5->google-colab) (5.10.4)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.10/dist-packages (from notebook==6.5.5->google-colab) (6.5.4)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook==6.5.5->google-colab) (1.6.0)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook==6.5.5->google-colab) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook==6.5.5->google-colab) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook==6.5.5->google-colab) (0.20.0)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook==6.5.5->google-colab) (1.1.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas==2.0.3->google-colab) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas==2.0.3->google-colab) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas==2.0.3->google-colab) (1.25.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->google-colab) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->google-colab) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->google-colab) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->google-colab) (2024.6.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython==7.34.0->google-colab) (0.8.4)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.6.1->notebook==6.5.5->google-colab) (4.2.2)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook==6.5.5->google-colab) (0.2.4)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook==6.5.5->google-colab) (4.9.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook==6.5.5->google-colab) (4.12.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook==6.5.5->google-colab) (6.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook==6.5.5->google-colab) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook==6.5.5->google-colab) (0.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook==6.5.5->google-colab) (2.1.5)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook==6.5.5->google-colab) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook==6.5.5->google-colab) (0.10.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook==6.5.5->google-colab) (24.1)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook==6.5.5->google-colab) (1.5.1)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook==6.5.5->google-colab) (1.3.0)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook==6.5.5->google-colab) (2.20.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook==6.5.5->google-colab) (4.19.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython==7.34.0->google-colab) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython==7.34.0->google-colab) (0.2.13)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth==2.27.0->google-colab) (0.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.1->ipyparallel==8.8.0->google-colab) (1.16.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook==6.5.5->google-colab) (21.2.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook==6.5.5->google-colab) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook==6.5.5->google-colab) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook==6.5.5->google-colab) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook==6.5.5->google-colab) (0.18.1)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.10/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook==6.5.5->google-colab) (1.24.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook==6.5.5->google-colab) (1.16.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=5->notebook==6.5.5->google-colab) (2.5)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert>=5->notebook==6.5.5->google-colab) (0.5.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook==6.5.5->google-colab) (2.22)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook==6.5.5->google-colab) (3.7.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook==6.5.5->google-colab) (1.8.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook==6.5.5->google-colab) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook==6.5.5->google-colab) (1.2.1)\n",
            "Installing collected packages: jedi\n",
            "Successfully installed jedi-0.19.1\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (3.9.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.4)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from h5py) (1.25.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.11.4)\n",
            "Collecting imblearn\n",
            "  Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.10/dist-packages (from imblearn) (0.10.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn->imblearn) (1.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn->imblearn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn->imblearn) (3.5.0)\n",
            "Installing collected packages: imblearn\n",
            "Successfully installed imblearn-0.0\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "# == Install requirements ==\n",
        "\n",
        "!pip install google-colab\n",
        "!pip install tensorflow keras numpy\n",
        "!pip install h5py tqdm\n",
        "!pip install pandas scipy imblearn\n",
        "!pip install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "UD4mNESiD965"
      },
      "outputs": [],
      "source": [
        "# == Import requirements ==\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import logging\n",
        "\n",
        "from google.colab import drive, files\n",
        "import os\n",
        "import h5py\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "\n",
        "import random\n",
        "import scipy\n",
        "from scipy.signal import butter, lfilter\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import shutil\n",
        "from itertools import zip_longest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "rcryqS0FDqBV"
      },
      "outputs": [],
      "source": [
        "# == Preprocess functions ==\n",
        "\n",
        "def pad_or_truncate_ecg(ecg: list, max_samples: int) -> list:\n",
        "    try:\n",
        "        padded_or_truncated_ecg = ecg[:max_samples] + [0] * (max_samples - len(ecg))\n",
        "    except Exception as e:\n",
        "        print(\"Fail: padding\", e)\n",
        "    return padded_or_truncated_ecg\n",
        "\n",
        "def resample_ecg(ecg: list, resample: int):\n",
        "    new_ecg = scipy.signal.resample(\n",
        "        ecg, resample, t=None, axis=0, window=None, domain=\"time\"\n",
        "    )\n",
        "    return list(new_ecg)\n",
        "\n",
        "def normalize_to_minus11(ecg: list):\n",
        "    max_val = max(ecg)\n",
        "    min_val = min(ecg)\n",
        "    # Handle the case where max_val and min_val are the same (to avoid division by zero)\n",
        "    if max_val == min_val:\n",
        "        return [0 for _ in ecg]\n",
        "    normalized_values = [2 * (x - min_val) / (max_val - min_val) - 1 for x in ecg]\n",
        "    return normalized_values\n",
        "\n",
        "def butter_bandpass(lowcut, highcut, fs, order=4):\n",
        "    nyquist = 0.5 * fs\n",
        "    low = lowcut / nyquist\n",
        "    high = highcut / nyquist\n",
        "    b, a = butter(order, [low, high], btype=\"band\")\n",
        "    return b, a\n",
        "\n",
        "def butter_bandpass_filter(ecg: list, lowcut: float, highcut: float, sampling_rate: int, order: int =4):\n",
        "    b, a = butter_bandpass(lowcut, highcut, sampling_rate, order=order)\n",
        "    y = lfilter(b, a, ecg)\n",
        "    return y\n",
        "\n",
        "def split_list_into_n_sublists(lst, n):\n",
        "    k, m = divmod(len(lst), n)\n",
        "    return [lst[i * k + min(i, m):(i + 1) * k + min(i + 1, m)] for i in range(n)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "g3IMoWUCkMc5"
      },
      "outputs": [],
      "source": [
        "# == Map labels to numerical values functions ==\n",
        "\n",
        "# Official scored labels Physionet 2021: https://github.com/physionetchallenges/evaluation-2021/blob/main/dx_mapping_scored.csv\n",
        "\n",
        "arrhyhtmia_mapping_id_to_index = {\n",
        "    \"426783006\": 0, # sinus rhythm (SR)\n",
        "    \"164889003\": 1, # atrial fibrillation (AF)\n",
        "    \"164890007\": 2, # atrial flutter (AFL)\n",
        "    \"284470004\": 3, # premature atrial contraction (PAC)\n",
        "    \"63593006\": 3, # supraventricular premature beats (SVPB)\n",
        "    \"427172004\": 4, # premature ventricular contractions (PVC)\n",
        "    \"17338001\": 4, # ventricular premature beats (VPB)\n",
        "    \"6374002\": 5, # bundle branch block (BBB)\n",
        "    \"426627000\": 6, # bradycardia (Brady)\n",
        "    \"733534002\": 7, # complete left bundle branch block (CLBBB)\n",
        "    \"164909002\": 7, # left bundle branch block (LBBB)\n",
        "    \"713427006\": 8, # complete right bundle branch block (CRBBB)\n",
        "    \"59118001\": 8, # right bundle branch block (RBBB)\n",
        "    \"270492004\": 9, # 1st degree av block (IAVB)\n",
        "    \"713426002\": 10, # incomplete right bundle branch block (IRBBB)\n",
        "    \"39732003\": 11, # left axis deviation (LAD)\n",
        "    \"445118002\": 12, # left anterior fascicular block (LAnFB)\n",
        "    \"251146004\": 13, # low qrs voltages (LQRSV)\n",
        "    \"698252002\": 14, # nonspecific intraventricular conduction disorder (NSIVCB)\n",
        "    \"10370003\": 15, # pacing rhythm (PR)\n",
        "    \"365413008\": 16, # poor R wave Progression (PRWP)\n",
        "    \"164947007\": 17, # prolonged pr interval (LPR)\n",
        "    \"111975006\": 18, # prolonged qt interval (LQT)\n",
        "    \"164917005\": 19, # qwave abnormal (QAb)\n",
        "    \"47665007\": 20,  # right axis deviation (RAD)\n",
        "    \"427393009\": 21, # sinus arrhythmia (SA)\n",
        "    \"426177001\": 22, # sinus bradycardia (SB)\n",
        "    \"427084000\": 23, # sinus tachycardia (STach)\n",
        "    \"164934002\": 24, # t wave abnormal (TAb)\n",
        "    \"59931005\": 25 # t wave inversion (TInv)\n",
        "}\n",
        "\n",
        "def map_arrhyhtmia_id_to_index(x: str) -> int:\n",
        "    return arrhyhtmia_mapping_id_to_index[x]\n",
        "\n",
        "arrhyhtmia_mapping_index_to_id = {\n",
        "    0: \"426783006\", # sinus rhythm (SR)\n",
        "    1: \"164889003\", # atrial fibrillation (AF)\n",
        "    2: \"164890007\", # atrial flutter (AFL)\n",
        "    3: \"284470004|63593006\", # premature atrial contraction (PAC) | supraventricular premature beats (SVPB)\n",
        "    4: \"427172004|17338001\", # premature ventricular contractions (PVC) | ventricular premature beats (VPB)\n",
        "    5: \"6374002\", # bundle branch block (BBB)\n",
        "    6: \"426627000\", # bradycardia (Brady)\n",
        "    7: \"733534002|164909002\", # complete left bundle branch block (CLBBB) | left bundle branch block (LBBB)\n",
        "    8: \"713427006|59118001\", # complete right bundle branch block (CRBBB) | right bundle branch block (RBBB)\n",
        "    9: \"270492004\", # 1st degree av block (IAVB)\n",
        "    10: \"713426002\", # incomplete right bundle branch block (IRBBB)\n",
        "    11: \"39732003\", # left axis deviation (LAD)\n",
        "    12: \"445118002\", # left anterior fascicular block (LAnFB)\n",
        "    13: \"251146004\", # low qrs voltages (LQRSV)\n",
        "    14: \"698252002\", # nonspecific intraventricular conduction disorder (NSIVCB)\n",
        "    15: \"10370003\", # pacing rhythm (PR)\n",
        "    16: \"365413008\", # poor R wave Progression (PRWP)\n",
        "    17: \"164947007\", # prolonged pr interval (LPR)\n",
        "    18: \"111975006\", # prolonged qt interval (LQT)\n",
        "    19: \"164917005\", # qwave abnormal (QAb)\n",
        "    20: \"47665007\",  # right axis deviation (RAD)\n",
        "    21: \"427393009\", # sinus arrhythmia (SA)\n",
        "    22: \"426177001\", # sinus bradycardia (SB)\n",
        "    23: \"427084000\", # sinus tachycardia (STach)\n",
        "    24: \"164934002\", # t wave abnormal (TAb)\n",
        "    25: \"59931005\" # t wave inversion (TInv)\n",
        "}\n",
        "\n",
        "# arrhyhtmia_mapping_index_to_id = dict(map(reversed, arrhyhtmia_mapping_id_to_index.items()))\n",
        "\n",
        "def map_arrhyhtmia_index_to_id(x: int) -> str:\n",
        "    return arrhyhtmia_mapping_index_to_id[x]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZTY2UE1Mhlj",
        "outputId": "7d244aea-c7da-4f17-cd7f-a3b917697e0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "codes_SNOMED.csv  physionet2017_references.csv\tphysionet2021_references.csv\n",
            "physionet2017.h5  physionet2021.h5\t\tprepared\n"
          ]
        }
      ],
      "source": [
        "# == Mount drive ==\n",
        "\n",
        "# https://drive.google.com/drive/folders/1L_gOMrkygu2N0k97COYuVrmE-AwEEMoQ\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "path = \"/content/drive/My Drive/Master Thesis/Datasets\"\n",
        "!ls \"/content/drive/My Drive/Master Thesis/Datasets\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ejP3dsia8Wdq"
      },
      "outputs": [],
      "source": [
        "# == Load all Physionet2021 ECGs and their IDs to a dictionary X_dict ==\n",
        "\n",
        "X_dict = {}\n",
        "Y_dict = {}\n",
        "\n",
        "h5file = h5py.File(os.path.join(path, \"prepared/physionet2021_scoredLabels.h5\"), \"r\")\n",
        "IDs = list(h5file.keys())\n",
        "pbar = tqdm(total=len(IDs), desc=\"Load ECG data\", position=0, leave=True)\n",
        "for key in IDs:\n",
        "    X_dict[key] = list(h5file[key][0])\n",
        "    pbar.update(1)\n",
        "\n",
        "# == Load all labels and their IDs to a dictionary Y_dict (some ECGs can have multiple labels) ==\n",
        "\n",
        "labels_df = pd.read_csv(os.path.join(path, \"physionet2021_references.csv\"), sep=\";\")\n",
        "pbar = tqdm(total=len(labels_df), desc=\"Load ECG labels\", position=0, leave=True)\n",
        "for _, row in labels_df.iterrows():\n",
        "    labels = row[\"labels\"].strip().split(\",\")\n",
        "    binary_crossentropy_labels = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "    for label in labels:\n",
        "        if label in VALID_LABELS:\n",
        "              binary_crossentropy_labels[(map_arrhyhtmia_id_to_index(label))] = 1\n",
        "    if row[\"id\"] in X_dict:\n",
        "        Y_dict[row[\"id\"]] = binary_crossentropy_labels\n",
        "    pbar.update(1)\n",
        "\n",
        "# del IDs, h5file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yibThGeHx5U7"
      },
      "outputs": [],
      "source": [
        "# == Preprocess ECGs ==\n",
        "\n",
        "pbar = tqdm(total=len(X_dict), desc=\"Preprocess ECGs\", position=0, leave=True)\n",
        "for key in X_dict:\n",
        "    X_dict[key] = pad_or_truncate_ecg(ecg=X_dict[key], max_samples=5000)\n",
        "    X_dict[key] = resample_ecg(ecg=X_dict[key], resample=2000)\n",
        "    X_dict[key] = normalize_to_minus11(ecg=X_dict[key])\n",
        "    X_dict[key] = butter_bandpass_filter(ecg=X_dict[key], lowcut=0.3, highcut=21.0, sampling_rate=200)\n",
        "    pbar.update(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UkTDLTJy9ku0"
      },
      "outputs": [],
      "source": [
        "# == Map scored labels to ECGs and create three lists (X: ECGs, Y: labels, Z: IDs) ==\n",
        "\n",
        "X = []\n",
        "Y = []\n",
        "Z = []\n",
        "\n",
        "for patient_id in tqdm(Y_dict, desc=\"Map labels to ECGs\", position=0, leave=True):\n",
        "      X.append(X_dict[patient_id])\n",
        "      Y.append(Y_dict[patient_id])\n",
        "      Z.append(str(patient_id))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oH1on-V7RJ1s"
      },
      "outputs": [],
      "source": [
        "# == Shuffle data, convert to numpy lists and reshape ==\n",
        "\n",
        "# Shuffle data\n",
        "combined = list(zip(X, Y, Z))\n",
        "random.shuffle(combined)\n",
        "X, Y, Z = zip(*combined)\n",
        "X = list(X)\n",
        "Y = list(Y)\n",
        "Z = list(Z)\n",
        "\n",
        "# Convert to numpy lists\n",
        "for index, x in enumerate(X):\n",
        "    X[index] = np.array(x)\n",
        "X = np.array(X)\n",
        "\n",
        "for index, y in enumerate(Y):\n",
        "    Y[index] = np.array(y)\n",
        "Y = np.array(Y)\n",
        "\n",
        "Z = np.array(Z)\n",
        "\n",
        "# Reshape\n",
        "X = X.reshape((-1, 2000, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eEsV9r0EjSTw"
      },
      "outputs": [],
      "source": [
        "# == A-B-testing models ==\n",
        "\n",
        "# Model A: Residual_CNN_1lead\n",
        "def conv(i, filters=16, kernel_size=9, strides=1):\n",
        "    i = keras.layers.Conv1D(\n",
        "        filters=filters, kernel_size=kernel_size, strides=strides, padding=\"same\"\n",
        "    )(i)\n",
        "    i = keras.layers.BatchNormalization()(i)\n",
        "    i = keras.layers.LeakyReLU()(i)\n",
        "    i = keras.layers.SpatialDropout1D(0.1)(i)\n",
        "    return i\n",
        "def residual_unit(x, filters, layers=3):\n",
        "    inp = x\n",
        "    for i in range(layers):\n",
        "        x = conv(x, filters)\n",
        "    return keras.layers.add([x, inp])\n",
        "def conv_block(x, filters, strides):\n",
        "    x = conv(x, filters)\n",
        "    x = residual_unit(x, filters)\n",
        "    if strides > 1:\n",
        "        x = keras.layers.AveragePooling1D(strides, strides)(x)\n",
        "    return x\n",
        "def build_model_A(input_shape, num_classes):\n",
        "    inp = keras.layers.Input(input_shape)\n",
        "    x = inp\n",
        "    x = conv_block(x, 16, 4)\n",
        "    x = conv_block(x, 16, 4)\n",
        "    x = conv_block(x, 32, 4)\n",
        "    x = conv_block(x, 32, 4)\n",
        "    x = keras.layers.Masking(mask_value=0)(x)\n",
        "    x = keras.layers.GRU(128, recurrent_dropout=0.1)(x)\n",
        "    x = keras.layers.Dense(num_classes, activation=\"sigmoid\")(x)\n",
        "    model = keras.models.Model(inp, x)\n",
        "    return model\n",
        "\n",
        "# Model B: CNN_Transformer_1lead\n",
        "def build_model_B(num_classes, input_shape):\n",
        "    # input_shape = (2000, 1)  # Each sample has 2000 timesteps and 1 feature per timestep\n",
        "    input_layer = keras.layers.Input(input_shape)\n",
        "\n",
        "    # Masking for padded/truncated data\n",
        "    i = keras.layers.Masking(mask_value=0)(input_layer)\n",
        "    # Conv1\n",
        "    i = keras.layers.Conv1D(filters=16, kernel_size=9, strides=1, padding=\"same\")(i)\n",
        "    i = keras.layers.BatchNormalization()(i)\n",
        "    i = keras.layers.ReLU()(i)\n",
        "    i = keras.layers.SpatialDropout1D(0.1)(i)\n",
        "    i = keras.layers.AveragePooling1D(2)(i)\n",
        "    # Conv2\n",
        "    i = keras.layers.Conv1D(filters=32, kernel_size=9, strides=1, padding=\"same\")(i)\n",
        "    i = keras.layers.BatchNormalization()(i)\n",
        "    i = keras.layers.ReLU()(i)\n",
        "    i = keras.layers.SpatialDropout1D(0.1)(i)\n",
        "    i = keras.layers.AveragePooling1D(2)(i)\n",
        "    # Conv3\n",
        "    i = keras.layers.Conv1D(filters=64, kernel_size=9, strides=1, padding=\"same\")(i)\n",
        "    i = keras.layers.BatchNormalization()(i)\n",
        "    i = keras.layers.ReLU()(i)\n",
        "    i = keras.layers.SpatialDropout1D(0.1)(i)\n",
        "    i = keras.layers.AveragePooling1D(2)(i)\n",
        "    # Channel Average Pooling and Reshaping\n",
        "    i = keras.layers.GlobalAveragePooling1D(data_format=\"channels_first\")(i)\n",
        "    i = keras.layers.Reshape((5, 50))(i)\n",
        "    # Encoder block/Attention mechanisms\n",
        "    i = transformer_encoder(i, input_shape=(5, 50), key_dim=50, num_heads=1, ff_dim=24, dropout=0.1)\n",
        "    i = transformer_encoder(i, input_shape=(5, 50), key_dim=50, num_heads=1, ff_dim=24, dropout=0.1)\n",
        "    i = transformer_encoder(i, input_shape=(5, 50), key_dim=50, num_heads=1, ff_dim=24, dropout=0.1)\n",
        "    # Flatten\n",
        "    i = keras.layers.Flatten()(i)\n",
        "    # Feedforward Softmax\n",
        "    i = keras.layers.Dense(num_classes, activation=\"sigmoid\")(i)\n",
        "    return keras.models.Model(inputs=input_layer, outputs=i)\n",
        "\n",
        "# Model C: vanilla_Transformer_1lead\n",
        "def transformer_encoder(input, input_shape, num_heads, key_dim, ff_dim, dropout):\n",
        "    # Multi-Head Attention\n",
        "    x = keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=key_dim, dropout=dropout, kernel_regularizer=regularizers.l2(0.001))(input, input)\n",
        "    # Add & Normalize\n",
        "    res = x + input\n",
        "    x = keras.layers.LayerNormalization(epsilon=1e-6)(res)\n",
        "    # Feed-Forward Layer\n",
        "    x = keras.layers.Flatten(input_shape=input_shape)(x)\n",
        "    x = keras.layers.Dense(units=ff_dim, activation='relu', kernel_regularizer=regularizers.l2(0.001))(x)\n",
        "    x = keras.layers.Dense(input_shape[0] * input_shape[1], kernel_regularizer=regularizers.l2(0.001))(x)\n",
        "    x = keras.layers.Reshape(input_shape)(x)\n",
        "    x = keras.layers.Dropout(rate=dropout)(x)\n",
        "    # Add & Normalize\n",
        "    x = x + res\n",
        "    x = keras.layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "    return x\n",
        "\n",
        "def get_positional_encoding(seq_length, d_model):\n",
        "    position = np.arange(seq_length)[:, np.newaxis]\n",
        "    div_term = np.exp(np.arange(0, d_model, 2) * -(np.log(10000.0) / d_model))\n",
        "    pe = np.zeros((seq_length, d_model))\n",
        "    pe[:, 0::2] = np.sin(position * div_term)\n",
        "    pe[:, 1::2] = np.cos(position * div_term)\n",
        "    pe = pe[np.newaxis, :]\n",
        "    return tf.constant(pe, dtype=tf.float32)\n",
        "\n",
        "def build_model_C(num_classes, input_shape, positional_encoding, num_encoder_blocks, num_heads, key_dim, ff_dim, dropout):\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    x = inputs\n",
        "    if positional_encoding:\n",
        "        positional_encoding_values = get_positional_encoding(input_shape[0], input_shape[1])\n",
        "        x = x + positional_encoding_values\n",
        "    for _ in range(num_encoder_blocks):\n",
        "        x = transformer_encoder(x, input_shape, key_dim, num_heads, ff_dim, dropout)\n",
        "    x = keras.layers.Flatten(input_shape=input_shape)(x)\n",
        "    outputs = keras.layers.Dense(num_classes, activation='sigmoid')(x)\n",
        "    return keras.Model(inputs, outputs)\n",
        "\n",
        "# Model D: channel_attention_1lead\n",
        "from tensorflow.keras.layers import Input, Conv1D, GlobalAveragePooling1D, GlobalMaxPooling1D, Dense, Multiply, Add, Activation\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "def channel_attention(input_feature, ratio=8):\n",
        "    channel = input_feature.shape[-1]\n",
        "\n",
        "    shared_layer_one = Dense(channel//ratio, activation='relu', kernel_initializer='he_normal', use_bias=True, bias_initializer='zeros')\n",
        "    shared_layer_two = Dense(channel, kernel_initializer='he_normal', use_bias=True, bias_initializer='zeros')\n",
        "\n",
        "    avg_pool = GlobalAveragePooling1D()(input_feature)\n",
        "    avg_pool = shared_layer_one(avg_pool)\n",
        "    avg_pool = shared_layer_two(avg_pool)\n",
        "\n",
        "    max_pool = GlobalMaxPooling1D()(input_feature)\n",
        "    max_pool = shared_layer_one(max_pool)\n",
        "    max_pool = shared_layer_two(max_pool)\n",
        "\n",
        "    cbam_feature = Add()([avg_pool, max_pool])\n",
        "    cbam_feature = Activation('sigmoid')(cbam_feature)\n",
        "\n",
        "    return Multiply()([input_feature, cbam_feature])\n",
        "\n",
        "def build_model_D(input_shape, num_classes):\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    x = Conv1D(64, kernel_size=3, padding='same', activation='relu')(inputs)\n",
        "    x = channel_attention(x)\n",
        "\n",
        "    x = Conv1D(128, kernel_size=3, padding='same', activation='relu')(x)\n",
        "    x = channel_attention(x)\n",
        "\n",
        "    x = Conv1D(256, kernel_size=3, padding='same', activation='relu')(x)\n",
        "    x = channel_attention(x)\n",
        "\n",
        "    x = GlobalAveragePooling1D()(x)\n",
        "    outputs = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs, outputs)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3co4ms3pw4f6"
      },
      "outputs": [],
      "source": [
        "# == Initialize model ==\n",
        "\n",
        "# Explicitly specify the GPU device\n",
        "\n",
        "physical_devices = tf.config.experimental.list_physical_devices(\"GPU\")\n",
        "if len(physical_devices) > 0:\n",
        "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
        "\n",
        "num_encoder_blocks = 8 # 1 8\n",
        "positional_encoding = False # True False\n",
        "num_heads = 1 # 1 8\n",
        "key_dim = 25 # 25\n",
        "ff_dim = 24 # 24 2048\n",
        "dropout = 0.1 # 0.1 0.4\n",
        "input_shape = X.shape\n",
        "\n",
        "# Check if a GPU is available\n",
        "print(\"Number of GPUs available:\", len(tf.config.experimental.list_physical_devices(\"GPU\")))\n",
        "print(f\"Number of training data examples: {len(X)}\")\n",
        "print(f\"Number of classes: {NUM_CLASSES}\")\n",
        "print(f\"Shape of training data: {input_shape}\")\n",
        "print(f\"Epochs: {EPOCHS}\")\n",
        "print(f\"Learning rate: {LEARNING_RATE}\")\n",
        "print(f\"Batch size: {BATCH_SIZE}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zmp-isCF5Fi8"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    if os.path.exists(\"models\"):\n",
        "        shutil.rmtree(\"models\")\n",
        "    os.makedirs(\"models\")\n",
        "except OSError as e:\n",
        "    print(f\"Error: {e.strerror}\")\n",
        "\n",
        "try:\n",
        "    if os.path.exists(\"test_outputs\"):\n",
        "        shutil.rmtree(\"test_outputs\")\n",
        "    os.makedirs(\"test_outputs\")\n",
        "except OSError as e:\n",
        "    print(f\"Error: {e.strerror}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "btGG3vIB46V4"
      },
      "outputs": [],
      "source": [
        "# == Save predictions util functin ==\n",
        "\n",
        "def save_predictions(pred, pred_prob, z_test):\n",
        "    pbar = tqdm(total=len(pred), desc=\"Convert test_outputs\", position=0, leave=True)\n",
        "    for index, prediction in enumerate(tqdm(zip(pred, pred_prob))):\n",
        "        pbar.update(1)\n",
        "        new_file = \"#\"\n",
        "        new_file += z_test[index] + \"\\n\"\n",
        "        # ids\n",
        "        for pred_index, _ in enumerate(prediction[0]):\n",
        "            new_file += map_arrhyhtmia_index_to_id(pred_index) + \",\"\n",
        "        new_file = new_file[:-1] + \"\\n\"\n",
        "        # pred\n",
        "        for pred_index, _ in enumerate(prediction[0]):\n",
        "            if prediction[0][pred_index] == 1:\n",
        "                value = \"True\"\n",
        "            elif prediction[0][pred_index] == 0:\n",
        "                value = \"False\"\n",
        "            new_file += value + \",\"\n",
        "        new_file = new_file[:-1] + \"\\n\"\n",
        "        # pred_prob\n",
        "        for pred_index, _ in enumerate(prediction[1]):\n",
        "            new_file += str(prediction[1][pred_index]) + \",\"\n",
        "        new_file = new_file[:-1]\n",
        "        with open(f\"test_outputs/{z_test[index]}.csv\", \"w\", encoding=\"utf-8\") as file:\n",
        "            file.write(new_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v_8Bb2yWJAy5"
      },
      "outputs": [],
      "source": [
        "# == Plot distribution util functin ==\n",
        "\n",
        "def plot_distribution(Y):\n",
        "    extracted_labels_testset = []\n",
        "    for label in Y:\n",
        "        for index, _ in enumerate(label):\n",
        "            if label[index]:\n",
        "                extracted_labels_testset.append(index)\n",
        "\n",
        "    label_counts = Counter(extracted_labels_testset)\n",
        "    print(label_counts)\n",
        "    combined = list(zip(label_counts.keys(), label_counts.values()))\n",
        "    combined.sort(key=lambda x: x[1], reverse=True)\n",
        "    label_keys, label_values = zip(*combined)\n",
        "    label_keys = list(label_keys)\n",
        "    label_values = list(label_values)\n",
        "\n",
        "    label_keys = list(map(lambda x: str(x), label_keys))\n",
        "\n",
        "    # for index, key in enumerate(label_keys):\n",
        "    #    label_keys[index] = str(index + 1) + \". \" + key[0].upper() + key[1:]\n",
        "\n",
        "    plt.figure(figsize=(30, 10))\n",
        "    plt.bar(label_keys, label_values, color=\"#1f77b4\")\n",
        "    plt.title(\"Physionet 2021 labels\")\n",
        "    plt.xlabel(\"Arrhythmia type\", labelpad=7)\n",
        "    plt.ylabel(\"Occurence\")\n",
        "    plt.xticks(rotation=45, ha=\"right\", fontsize=16)  # (rotation='diagional')\n",
        "    bars = plt.bar(label_keys, label_values, color=\"#1f77b4\")\n",
        "    # Adding the counts on top of the bars\n",
        "    for bar in bars:\n",
        "        yval = bar.get_height()\n",
        "        plt.text(\n",
        "            bar.get_x() + bar.get_width() / 2,\n",
        "            yval + 5,\n",
        "            yval,\n",
        "            ha=\"center\",\n",
        "            va=\"bottom\",\n",
        "            fontsize=16,\n",
        "        )\n",
        "\n",
        "    plt.show()\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YlKSZZq2wFGN"
      },
      "outputs": [],
      "source": [
        "# == Train model ==\n",
        "\n",
        "# Suppress TensorFlow logging\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "logging.getLogger('tensorflow').setLevel(logging.FATAL)\n",
        "\n",
        "# Initialize KFold\n",
        "fold_counter = 1\n",
        "n_folds = 10\n",
        "kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
        "metrics = {\n",
        "    \"accuracy\": [],\n",
        "    \"precision\": [],\n",
        "    \"recall\": [],\n",
        "    \"f1\": []\n",
        "}\n",
        "\n",
        "EPOCHS = 50\n",
        "\n",
        "# Cross-validation\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = Y[train_index], Y[test_index]\n",
        "    z_train, z_test = Z[train_index], Z[test_index]\n",
        "\n",
        "    callbacks = [\n",
        "        keras.callbacks.ModelCheckpoint(f\"Model_{NUM_CLASSES}classes.h5\", save_best_only=True, monitor=\"loss\"),\n",
        "        keras.callbacks.ReduceLROnPlateau(monitor=\"loss\", factor=0.5, patience=5, min_lr=0.000005),\n",
        "        keras.callbacks.EarlyStopping(monitor=\"loss\", patience=5, verbose=1),\n",
        "    ]\n",
        "    optimizer = Adam(learning_rate=LEARNING_RATE)\n",
        "    model = build_model_A(num_classes=NUM_CLASSES, input_shape=input_shape[1:])\n",
        "    # model = build_model_C(num_classes=NUM_CLASSES, input_shape=input_shape[1:], positional_encoding=positional_encoding, num_encoder_blocks=num_encoder_blocks, num_heads=num_heads, key_dim=key_dim, ff_dim=ff_dim, dropout=dropout)\n",
        "    # model.summary()\n",
        "    model.compile(optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "    history = model.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=EPOCHS, validation_split=0.8, callbacks=callbacks, verbose=1)\n",
        "\n",
        "    model.save(f\"models/{fold_counter}\")\n",
        "    fold_counter += 1\n",
        "\n",
        "    # Predict probabilities\n",
        "    pred_prob = model.predict(X_test)\n",
        "    # Binarize predictions using a threshold\n",
        "    threshold = 0.5\n",
        "    pred = (pred_prob > threshold).astype(int)\n",
        "\n",
        "    accuracy = accuracy_score(y_test, pred)\n",
        "    precision = precision_score(y_test, pred, average='weighted')\n",
        "    recall = recall_score(y_test, pred, average='weighted')\n",
        "    f1 = f1_score(y_test, pred, average='weighted')\n",
        "\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"F1-score: {f1:.4f}\")\n",
        "\n",
        "    print(\"Save predictions...\")\n",
        "    save_predictions(pred, pred_prob, z_test)\n",
        "    print(\"...finished saving.\")\n",
        "\n",
        "    metrics[\"accuracy\"].append(accuracy)\n",
        "    metrics[\"precision\"].append(precision)\n",
        "    metrics[\"recall\"].append(recall)\n",
        "    metrics[\"f1\"].append(f1)\n",
        "\n",
        "# train_accuracy = history.history[\"accuracy\"] # list\n",
        "# val_accuracy = history.history[\"val_accuracy\"] # list\n",
        "# train_loss = history.history[\"loss\"] # list\n",
        "# val_loss = history.history[\"val_loss\"] # list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v4TeNl83xv3Q"
      },
      "outputs": [],
      "source": [
        "# Print the metrics for each fold\n",
        "# for i in range(n_folds):\n",
        "#    print(f\"Fold {i+1} - Accuracy: {metrics['accuracy'][i]:.4f}, Precision: {metrics['precision'][i]:.4f}, Recall: {metrics['recall'][i]:.4f}, F1-score: {metrics['f1'][i]:.4f}\")\n",
        "\n",
        "# Calculate and print average metrics\n",
        "avg_accuracy = np.mean(metrics[\"accuracy\"])\n",
        "avg_precision = np.mean(metrics[\"precision\"])\n",
        "avg_recall = np.mean(metrics[\"recall\"])\n",
        "avg_f1 = np.mean(metrics[\"f1\"])\n",
        "\n",
        "print(f\"Average - Accuracy: {avg_accuracy:.4f}, Precision: {avg_precision:.4f}, Recall: {avg_recall:.4f}, F1-score: {avg_f1:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_-W9N5eR9RTD"
      },
      "outputs": [],
      "source": [
        "folder_to_zip = \"models\"\n",
        "output_filename = 'models.zip'\n",
        "shutil.make_archive(output_filename.replace('.zip', ''), 'zip', folder_to_zip)\n",
        "files.download(output_filename)\n",
        "\n",
        "folder_to_zip = \"test_outputs\"\n",
        "output_filename = 'test_outputs.zip'\n",
        "shutil.make_archive(output_filename.replace('.zip', ''), 'zip', folder_to_zip)\n",
        "files.download(output_filename)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}